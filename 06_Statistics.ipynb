{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609f7e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/24 15:44:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/11/24 15:44:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pyspark\n",
    "\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(conf=myConf)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0383",
   "metadata": {},
   "source": [
    "# 변수의 성격\n",
    "\n",
    "빅데이터는 통계와 같은 이전의 방식으로 분석하기에는 잘 맞지 않는 대규모이거나 복잡한 성격의 데이터를 말한다.\n",
    "\n",
    "데이터는 숫자, 텍스트로 구분할 수 있다. 숫자 값은 정수나 소수로 표현되고, 년봉, 매출액, 관객수와 같이 '크다' 또는 '작다' 하는 의미가 있다. 반면에 텍스트는 분석하기 어려울 수 밖에 없고, 어떻게든 정량화하기 위해 단어의 빈도로 변환하고 있다.\n",
    "\n",
    "측정하는 변수는 크게 나누면 다음과 같다.\n",
    "\n",
    "(1) 명목변수 Nominal varaible는 남녀 성별과 같이 순서가 없이 이름이 있는 변수를 말한다. 검은색, 흰색, 파란색 등의 색이나 종로구, 영등포구 등 지역구가 명목변수의 예가 된다.\n",
    "\n",
    "(2) 순위변수 Ordinal variable은 어떤 순서가 있는 범주에 속하여 그 범주의 이름을 말한다. '초등학고', '중학교', '고등학교', '대학교'와 같이 구분하여 붙인 이름이 예가 되고, 하위 학교를 마치고 나면 다음 등급으로 진학하는 순서가 있다. 소득수준을 '차상위', '중위', '상위'로 구분하면 순위변수에 해당된다.\n",
    "\n",
    "(3) 여기서 범주를 등간격으로 간격변수 Interval variable이라고 한다. 자신의 느낌을 '좋다', '보통', '안좋다' 로 범주화하는 경우이다.\n",
    "\n",
    "(4) 키, 몸무게와 같이 연속 변수 Continuous variable이 있다.\n",
    "\n",
    "통계에서는 변수의 성격에 따라 적용되는 분석의 방법이 다를 수 밖에 없다. 예를 들어:\n",
    "\n",
    "이산 값인 경우 이산분포 (주사위를 던져서 나오는 수)\n",
    "빈도인 경우 포아송분포 (이산분포의 한 종류로 볼 수 있고, 단위 시간 또는 단위 공간에서 발생하는 횟수를 나타낸다. 예를 들면 특정시간에 도착하는 버스 수)\n",
    "연속 값인 경우 정규분포로 모델링하여 평균, 표준편차, 확률 등의 통계량을 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8319cdc",
   "metadata": {},
   "source": [
    "# 샘플링\n",
    "\n",
    "### 무작위 수\n",
    "통계에 무작위 수는 빼놓을 수 없는데, 분포는 무작위 수로부터 만들어 지고, 확률이 계산된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3262c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st random number on the basis of the seed 0.23796462709189137\n",
      "2nd random number on the basis of the seed 0.5442292252959519\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(3) #시드수를 지정하면 무작위 숫자가 정해짐. 시드를 지정안하면 운영체제의 시간을 가져가 진짜 무작위 수가 만들어진다.\n",
    "print(\"1st random number on the basis of the seed {}\".format(random.random()))\n",
    "print(\"2nd random number on the basis of the seed {}\".format(random.random()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f1daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st random number on the basis of the seed 0.563623950541005\n",
      "2nd random number on the basis of the seed 0.37260990067152633\n"
     ]
    }
   ],
   "source": [
    "#random.seed()\n",
    "random.seed()\n",
    "print(\"1st random number on the basis of the seed {}\".format(random.random()))\n",
    "print(\"2nd random number on the basis of the seed {}\".format(random.random()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58087615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55475619 0.12333716]\n",
      " [0.28483135 0.05630234]\n",
      " [0.1840477  0.25909925]]\n"
     ]
    }
   ],
   "source": [
    "# Numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 균등분포 상에서 무작위 숫자 만들기\n",
    "print (np.random.random((3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d265aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6071890745714797"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:05:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:05:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:05:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:05:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:05:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:05:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:06:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/11/24 17:06:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/11/24 17:06:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:06:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:06:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:06:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:06:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:06:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:06:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:06:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:06:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:06:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:07:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:07:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:07:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:07:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:07:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:07:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:07:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:07:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:07:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:07:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:07:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:07:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:08:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:08:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:08:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:08:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:08:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:08:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:08:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:08:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:08:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:08:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:08:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:08:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:09:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:09:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 17:09:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/24 17:09:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.17.99.4:51224\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    }
   ],
   "source": [
    "# 정규분포 상에서 무작위 숫자 만들기\n",
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13b18ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 0, 표준편차 1을 가지는 정규분포에서 200개 샘플\n",
    "comp1=np.random.normal(0, 1, size=200)\n",
    "\n",
    "# 평균 10, 표준편차 2, 샘플은 200의 정규분포를 생성\n",
    "comp2=np.random.normal(10, 2, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "844ed059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dice=[]\n",
    "for i in range(100):\n",
    "   dice.append(random.randrange(1,6+1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(dice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a218bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dice, bins = np.arange(0.5, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52bd2219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGfCAYAAAD/BbCUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcRklEQVR4nO3dfWxddf3A8c/d2l1b6CBjdG1DKVMnKEM0DAdD2RA3XcwCzgd0Pmw+RIljigtBkRDvImy6RESzuGT8MSGm2f6QIQahq9FtEJyyKRHHgyMMmEhdhqPdA7l02/n98QsNpXO73drvPWWvV3Iz7unpuZ9+e2jfObftLWRZlgUAQCKjqj0AAHByER8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBSNYPZedmyZXHPPffEU089FXV1dTFt2rT48Y9/HOeee27fPgsWLIi77rqr3/tNnTo1Nm/eXNFjHD58OP79739HQ0NDFAqFwYwHAFRJlmWxd+/eaGlpiVGjjn5tY1DxsXHjxli4cGFcfPHFcfDgwbj55ptj1qxZ8cQTT8Qpp5zSt9/HPvaxWL16dd/9MWPGVPwY//73v6O1tXUwYwEAObFz584466yzjrrPoOLjwQcf7Hd/9erV0djYGFu3bo3LL7+8b3uxWIympqbBHLpPQ0NDRPz/8GPHjj2uY4w0vb29sX79+pg1a1bU1tZWe5xcs1aVs1aVs1aVs1aVO9nWqqenJ1pbW/u+jx/NoOLjzbq7uyMiYty4cf22b9iwIRobG+P000+P6dOnx2233RaNjY1HPEa5XI5yudx3f+/evRERUVdXF3V1dScy3ohRU1MT9fX1UVdXd1KcoCfCWlXOWlXOWlXOWlXuZFur3t7eiIiKfmSikGVZdjwPkmVZXHXVVbFnz5546KGH+ravXbs2Tj311Ghra4sdO3bELbfcEgcPHoytW7dGsVgccJxSqRRLliwZsL29vT3q6+uPZzQAILEDBw7EvHnzoru7+5jPXBx3fCxcuDDuv//+ePjhh4/63M5LL70UbW1tsWbNmpg7d+6At7/5ysfrl2127959Uj3t0tnZGTNnzjwp6vhEWKvKWavKWavKWavKnWxr1dPTE+PHj68oPo7raZdFixbFfffdF5s2bTrmD5U0NzdHW1tbbN++/YhvLxaLR7wiUltbe1J8st7oZPyYj5e1qpy1qpy1qpy1qtzJslaD+RgHFR9ZlsWiRYti3bp1sWHDhpg4ceIx3+fll1+OnTt3RnNz82AeCgB4ixrUHxlbuHBh/OpXv4r29vZoaGiIrq6u6OrqildffTUiIvbt2xc33HBD/OlPf4rnnnsuNmzYEHPmzInx48fHJz7xiWH5AACAkWVQVz5WrlwZEREzZszot3316tWxYMGCGD16dDz++ONx9913xyuvvBLNzc1xxRVXxNq1ayv61RsA4K1v0E+7HE1dXV10dHSc0EAAwFub13YBAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkjuu1XYD+zvne/dUeYYDi6CyWfyBicqkjyoeO/RLXqTz3o49XewSgylz5AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgqZpqDwDA/3bO9+6v9gj9FEdnsfwDEZNLHVE+VKj2OP0896OPV3sEKuTKBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKQGFR/Lli2Liy++OBoaGqKxsTGuvvrqePrpp/vtk2VZlEqlaGlpibq6upgxY0Zs27ZtSIcGAEauQcXHxo0bY+HChbF58+bo7OyMgwcPxqxZs2L//v19+yxfvjxuv/32WLFiRTz66KPR1NQUM2fOjL179w758ADAyFMzmJ0ffPDBfvdXr14djY2NsXXr1rj88ssjy7K444474uabb465c+dGRMRdd90VEyZMiPb29vjGN74xdJMDACPSoOLjzbq7uyMiYty4cRERsWPHjujq6opZs2b17VMsFmP69OnxyCOPHDE+yuVylMvlvvs9PT0REdHb2xu9vb0nMt6I8frHebJ8vCcir2tVHJ1Ve4QBiqOyfv/mRd4+dxH5Pa8i8ndu5fW8isjf5y/P59VwGMzHWciy7LjOoCzL4qqrroo9e/bEQw89FBERjzzySFx22WXx4osvRktLS9++X//61+P555+Pjo6OAccplUqxZMmSAdvb29ujvr7+eEYDABI7cOBAzJs3L7q7u2Ps2LFH3fe4r3xcd9118fe//z0efvjhAW8rFAr97mdZNmDb62666aZYvHhx3/2enp5obW2NWbNmHXP4t4re3t7o7OyMmTNnRm1tbbXHybW8rtXk0sCwrrbiqCx+OOVw3LJlVJQPH/n/v2r4R+mj1R5hgLyeVxH5O7fyel5F5O/cyvN5NRxef+aiEscVH4sWLYr77rsvNm3aFGeddVbf9qampoiI6Orqiubm5r7tu3btigkTJhzxWMViMYrF4oDttbW1J8Un641Oxo/5eOVtrcqH8vVF+I3Khwu5mi9Pn7c3y9t5FZHfcytv51VEfs+tPJ5Xw2EwH+Ogftsly7K47rrr4p577ok//OEPMXHixH5vnzhxYjQ1NUVnZ2ffttdeey02btwY06ZNG8xDAQBvUYO68rFw4cJob2+P3/zmN9HQ0BBdXV0REXHaaadFXV1dFAqFuP7662Pp0qUxadKkmDRpUixdujTq6+tj3rx5w/IBAAAjy6DiY+XKlRERMWPGjH7bV69eHQsWLIiIiBtvvDFeffXV+OY3vxl79uyJqVOnxvr166OhoWFIBgYARrZBxUclvxhTKBSiVCpFqVQ63pkAgLcwr+0CACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkqqp9gCpnfO9+6s9wgDF0Vks/0DE5FJHlA8Vqj1On+d+9PFqjwDAW5ArHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBIatDxsWnTppgzZ060tLREoVCIe++9t9/bFyxYEIVCod/tkksuGap5AYARbtDxsX///rjwwgtjxYoV/3Ofj33sY/HSSy/13X73u9+d0JAAwFvHoF9Ybvbs2TF79uyj7lMsFqOpqami45XL5SiXy333e3p6IiKit7c3ent7BzveMRVHZ0N+zBNVHJX1+zcvhmP9T9TrM+VtNudV5fL2uYvI73kVkb9zK6/nVUT+Pn95Pq+Gw2A+zkKWZcd9BhUKhVi3bl1cffXVfdsWLFgQ9957b4wZMyZOP/30mD59etx2223R2Nh4xGOUSqVYsmTJgO3t7e1RX19/vKMBAAkdOHAg5s2bF93d3TF27Nij7jvk8bF27do49dRTo62tLXbs2BG33HJLHDx4MLZu3RrFYnHAMY505aO1tTV27959zOGPx+RSx5Af80QVR2XxwymH45Yto6J8uFDtcfr8o/TRao8wQG9vb3R2dsbMmTOjtra22uP0cV6NbNaqctaqcnleq+H4+t7T0xPjx4+vKD4G/bTLsVxzzTV9/z158uSYMmVKtLW1xf333x9z584dsH+xWDxilNTW1g7LN5fyoXydAG9UPlzI1Xx5+ub+ZsN1fhyvPH3e3ixv51WeWavKWavK5XGthuPr52COOey/atvc3BxtbW2xffv24X4oAGAEGPb4ePnll2Pnzp3R3Nw83A8FAIwAg37aZd++ffHMM8/03d+xY0c89thjMW7cuBg3blyUSqX45Cc/Gc3NzfHcc8/F97///Rg/fnx84hOfGNLBAYCRadDxsWXLlrjiiiv67i9evDgiIubPnx8rV66Mxx9/PO6+++545ZVXorm5Oa644opYu3ZtNDQ0DN3UAMCINej4mDFjRhztF2Q6OvL3U/8AQH54bRcAICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFKDjo9NmzbFnDlzoqWlJQqFQtx777393p5lWZRKpWhpaYm6urqYMWNGbNu2bajmBQBGuEHHx/79++PCCy+MFStWHPHty5cvj9tvvz1WrFgRjz76aDQ1NcXMmTNj7969JzwsADDy1Qz2HWbPnh2zZ88+4tuyLIs77rgjbr755pg7d25ERNx1110xYcKEaG9vj2984xsnNi0AMOINOj6OZseOHdHV1RWzZs3q21YsFmP69OnxyCOPHDE+yuVylMvlvvs9PT0REdHb2xu9vb1DOd7/zzM6G/JjnqjiqKzfv3kxHOt/ol6fKW+zOa9GNmtVOWtVuTyv1XB8DR3MMQtZlh33qhQKhVi3bl1cffXVERHxyCOPxGWXXRYvvvhitLS09O339a9/PZ5//vno6OgYcIxSqRRLliwZsL29vT3q6+uPdzQAIKEDBw7EvHnzoru7O8aOHXvUfYf0ysfrCoVCv/tZlg3Y9rqbbropFi9e3He/p6cnWltbY9asWccc/nhMLg0MoGorjsrih1MOxy1bRkX58JHXqRr+UfpotUcYoLe3Nzo7O2PmzJlRW1tb7XH6OK9GNmtVOWtVuTyv1XB8fX/9mYtKDGl8NDU1RUREV1dXNDc3923ftWtXTJgw4YjvUywWo1gsDtheW1s7LN9cyofydQK8UflwIVfz5emb+5sN1/lxvPL0eXuzvJ1XeWatKmetKpfHtRqOr5+DOeaQ/p2PiRMnRlNTU3R2dvZte+2112Ljxo0xbdq0oXwoAGCEGvSVj3379sUzzzzTd3/Hjh3x2GOPxbhx4+Lss8+O66+/PpYuXRqTJk2KSZMmxdKlS6O+vj7mzZs3pIMDACPToONjy5YtccUVV/Tdf/3nNebPnx+//OUv48Ybb4xXX301vvnNb8aePXti6tSpsX79+mhoaBi6qQGAEWvQ8TFjxow42i/IFAqFKJVKUSqVTmQuAOAtymu7AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkqqp9gDk1znfu7/aIwxQHJ3F8g9ETC51RPlQodrjAHAcXPkAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApIY8PkqlUhQKhX63pqamoX4YAGCEqhmOg55//vnx+9//vu/+6NGjh+NhAIARaFjio6amxtUOAOCIhiU+tm/fHi0tLVEsFmPq1KmxdOnSePvb337EfcvlcpTL5b77PT09ERHR29sbvb29Qz5bcXQ25Mc8UcVRWb9/+d+sVeWsVeWsVeWsVeXyvFbD8f11MMcsZFk2pKvywAMPxIEDB+Jd73pX/Oc//4lbb701nnrqqdi2bVucccYZA/YvlUqxZMmSAdvb29ujvr5+KEcDAIbJgQMHYt68edHd3R1jx4496r5DHh9vtn///njHO94RN954YyxevHjA24905aO1tTV27959zOGPx+RSx5Af80QVR2XxwymH45Yto6J8uFDtcXLNWlXOWlXOWlXOWlUuz2v1j9JHh/yYPT09MX78+IriY1iednmjU045JS644ILYvn37Ed9eLBajWCwO2F5bWxu1tbVDPk/5UL5OgDcqHy7ker48sVaVs1aVs1aVs1aVy+NaDcf318Ecc9j/zke5XI4nn3wympubh/uhAIARYMjj44YbboiNGzfGjh074s9//nN86lOfip6enpg/f/5QPxQAMAIN+dMu//rXv+Jzn/tc7N69O84888y45JJLYvPmzdHW1jbUDwUAjEBDHh9r1qwZ6kMCAG8hXtsFAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhq2+PjFL34REydOjLe97W1x0UUXxUMPPTRcDwUAjCDDEh9r166N66+/Pm6++eb429/+Fh/60Idi9uzZ8cILLwzHwwEAI0jNcBz09ttvj69+9avxta99LSIi7rjjjujo6IiVK1fGsmXL+u1bLpejXC733e/u7o6IiP/+97/R29s75LPVHNw/5Mc8UTWHszhw4HDU9I6KQ4cL1R4n16xV5axV5axV5axV5fK8Vi+//PKQH3Pv3r0REZFl2bF3zoZYuVzORo8end1zzz39tn/rW9/KLr/88gH7/+AHP8giws3Nzc3Nze0tcNu5c+cxW2HIr3zs3r07Dh06FBMmTOi3fcKECdHV1TVg/5tuuikWL17cd//w4cPx3//+N84444woFPJVisOlp6cnWltbY+fOnTF27Nhqj5Nr1qpy1qpy1qpy1qpyJ9taZVkWe/fujZaWlmPuOyxPu0TEgHDIsuyIMVEsFqNYLPbbdvrppw/XWLk2duzYk+IEHQrWqnLWqnLWqnLWqnIn01qddtppFe035D9wOn78+Bg9evSAqxy7du0acDUEADj5DHl8jBkzJi666KLo7Ozst72zszOmTZs21A8HAIwww/K0y+LFi+OLX/xiTJkyJS699NJYtWpVvPDCC3HttdcOx8ONeMViMX7wgx8MePqJgaxV5axV5axV5axV5azV/1bIskp+J2bwfvGLX8Ty5cvjpZdeismTJ8dPf/rTuPzyy4fjoQCAEWTY4gMA4Ei8tgsAkJT4AACSEh8AQFLiAwBISnxU0aZNm2LOnDnR0tIShUIh7r333mqPlEvLli2Liy++OBoaGqKxsTGuvvrqePrpp6s9Vm6tXLky3vve9/b9VcVLL700HnjggWqPlXvLli2LQqEQ119/fbVHyaVSqRSFQqHframpqdpj5daLL74YX/jCF+KMM86I+vr6eN/73hdbt26t9li5IT6qaP/+/XHhhRfGihUrqj1Krm3cuDEWLlwYmzdvjs7Ozjh48GDMmjUr9u/P3ysU58FZZ50VP/rRj2LLli2xZcuW+PCHPxxXXXVVbNu2rdqj5dajjz4aq1ative+973VHiXXzj///HjppZf6bo8//ni1R8qlPXv2xGWXXRa1tbXxwAMPxBNPPBE/+clPTtqXDjmSYXttF45t9uzZMXv27GqPkXsPPvhgv/urV6+OxsbG2Lp1q78dcwRz5szpd/+2226LlStXxubNm+P888+v0lT5tW/fvvj85z8fd955Z9x6663VHifXampqXO2owI9//ONobW2N1atX920755xzqjdQDrnywYjT3d0dERHjxo2r8iT5d+jQoVizZk3s378/Lr300mqPk0sLFy6Mj3/84/GRj3yk2qPk3vbt26OlpSUmTpwYn/3sZ+PZZ5+t9ki5dN9998WUKVPi05/+dDQ2Nsb73//+uPPOO6s9Vq6ID0aULMti8eLF8cEPfjAmT55c7XFy6/HHH49TTz01isViXHvttbFu3bp4z3veU+2xcmfNmjXx17/+NZYtW1btUXJv6tSpcffdd0dHR0fceeed0dXVFdOmTYuXX3652qPlzrPPPhsrV66MSZMmRUdHR1x77bXxrW99K+6+++5qj5YbnnZhRLnuuuvi73//ezz88MPVHiXXzj333HjsscfilVdeiV//+tcxf/782LhxowB5g507d8a3v/3tWL9+fbztbW+r9ji598aniC+44IK49NJL4x3veEfcddddsXjx4ipOlj+HDx+OKVOmxNKlSyMi4v3vf39s27YtVq5cGV/60peqPF0+uPLBiLFo0aK477774o9//GOcddZZ1R4n18aMGRPvfOc7Y8qUKbFs2bK48MIL42c/+1m1x8qVrVu3xq5du+Kiiy6KmpqaqKmpiY0bN8bPf/7zqKmpiUOHDlV7xFw75ZRT4oILLojt27dXe5TcaW5uHhD67373u+OFF16o0kT548oHuZdlWSxatCjWrVsXGzZsiIkTJ1Z7pBEny7Iol8vVHiNXrrzyygG/rfHlL385zjvvvPjud78bo0ePrtJkI0O5XI4nn3wyPvShD1V7lNy57LLLBvw5gH/+85/R1tZWpYnyR3xU0b59++KZZ57pu79jx4547LHHYty4cXH22WdXcbJ8WbhwYbS3t8dvfvObaGhoiK6uroiIOO2006Kurq7K0+XP97///Zg9e3a0trbG3r17Y82aNbFhw4YBvzV0smtoaBjwc0OnnHJKnHHGGX6e6AhuuOGGmDNnTpx99tmxa9euuPXWW6Onpyfmz59f7dFy5zvf+U5MmzYtli5dGp/5zGfiL3/5S6xatSpWrVpV7dHyI6Nq/vjHP2YRMeA2f/78ao+WK0dao4jIVq9eXe3RcukrX/lK1tbWlo0ZMyY788wzsyuvvDJbv359tccaEaZPn559+9vfrvYYuXTNNddkzc3NWW1tbdbS0pLNnTs327ZtW7XHyq3f/va32eTJk7NisZidd9552apVq6o9Uq4UsizLqtQ9AMBJyA+cAgBJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJPV/CYhHbT1g1QsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pandas로 그리기\n",
    "\n",
    "import pandas as pd\n",
    "pd.Series(dice).hist(bins = np.arange(0.5, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a67032",
   "metadata": {},
   "source": [
    "# 히스토그램\n",
    "\n",
    "정규분포에서 무작위 샘플을 추출하는 randn()을 사용해서 histogram 그래프를 그려보자. 정규분포 샘플을 무작위로 100개 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5210bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 10 16 15 21 16  9  5  4  1]\n",
      "[-2.24085641 -1.7134083  -1.18596019 -0.65851207 -0.13106396  0.39638415\n",
      "  0.92383226  1.45128037  1.97872848  2.50617659  3.0336247 ]\n"
     ]
    }
   ],
   "source": [
    "x=np.random.randn(100)\n",
    "count, binends = np.histogram(x)\n",
    "print(count)\n",
    "print(binends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c56ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3., 10., 16., 15., 21., 16.,  9.,  5.,  4.,  1.]),\n",
       " array([-2.24085641, -1.7134083 , -1.18596019, -0.65851207, -0.13106396,\n",
       "         0.39638415,  0.92383226,  1.45128037,  1.97872848,  2.50617659,\n",
       "         3.0336247 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e991dd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정규분포 두개를 Series로 만들어 만들기\n",
    "\n",
    "values=pd.Series(np.concatenate( [comp1,comp2]))\n",
    "values.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbb4af7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d5bea",
   "metadata": {},
   "source": [
    "# 문제 S-1: 년도별 빈도 히스토그램\n",
    "빈도와 날자가 저장된 데이터에서 막대그래프를 그려보자. 아래 데이터의 첫 컬럼은 빈도, 둘째 컬럼은 날자이다. 막대그래프는 histogram, barchart를 선택할 수 있다.\n",
    "\n",
    "histogram은 한 변수(컬럼)의 빈도수.\n",
    "barchart는 두 변수간의 그래프."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27270672",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"30 14-11-2003\n",
    "10 15-03-2004\n",
    "12 04-12-2012\n",
    "33 09-05-2007\n",
    "44 16-08-2005\n",
    "55 25-07-2001\n",
    "76 31-12-2011\n",
    "87 25-06-2009\n",
    "118 16-02-2006\n",
    "119 10-02-2000\n",
    "145 03-05-2014\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8770c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "yvalues = []\n",
    "xdates = []\n",
    "for line in data.split(\"\\n\"):\n",
    "    x, y = line.split()\n",
    "    yvalues.append(int(x))\n",
    "    xdates.append(datetime.datetime.strptime(y, \"%d-%m-%Y\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7ab6bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 11 artists>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111) #3개의 숫자\n",
    "ax.bar(xdates, yvalues, width=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428ca4a",
   "metadata": {},
   "source": [
    "### boxplot\n",
    "전체 관측값을 정렬하고, 전체를 4분위로 나누면 IQR Interquatile Range을 구할 수 있다. \n",
    "Boxplot은 IQR의 Q1~Q3을 사각형으로 표시한다. pandas를 이용하거나, matplotlib으로 Boxplot을 그릴 수 있다. \n",
    "사각형의 주황색 선은 평균을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53bcd40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = np.random.normal(0,1,50) # mu=0, sigma=1, n=50\n",
    "x2 = np.random.normal(1,1,50)\n",
    "x3 = np.random.normal(2,1,50)\n",
    "plt.boxplot([x1,x2,x3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75c6f8",
   "metadata": {},
   "source": [
    "# 중심극한정리\n",
    "무작위로 평균 , 표준편차, 모집단이 있다고 하자. 모집단의 평균과 표준편차는 계산할 방법이 없어서 알 수가 없다. 표본을 추출하면, 모집단의 평균을 구할 수 있고, 모집단의 표준편차는 표본의 표준편차를 크기로 나누어 계산할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17c6d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\t: 0.060689233435796935\n",
      "median\t: -0.11510628732322738\n"
     ]
    }
   ],
   "source": [
    "x=np.random.randn(100)\n",
    "print (\"mean\\t: {}\".format(np.mean(x)))\n",
    "print (\"median\\t: {}\".format(np.median(x)))\n",
    "\n",
    "# 정규분포는 평균, 모드, 최빈값이 같아야 한다. \n",
    "# 아래는 평균은 0에 가깝고, 최빈값과 다소 차이가 있다. 정규분포의 솟거나, 퍼진 모양이 다르기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc456675",
   "metadata": {},
   "source": [
    "### skewness\n",
    "분포의 대칭성을 설명하는 지표로 skewness를 계산한다.  \n",
    "= 0 : 정규분포  \n",
    "&lt; 0 : +이면 +방향으로 꼬리가 있다. 왼쪽으로 피크가 있다.  \n",
    "&gt; 0 : -이면 -방향으로 꼬리가 있다. 오른쪽으로 피크가 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "762a3cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewness\t: 0.2385288503195637\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "print (\"skewness\\t: {}\".format(skew(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6d8e9",
   "metadata": {},
   "source": [
    "### kurtosis\n",
    "kurtosis는 분포의 뾰족한 정도를 설명한다.\n",
    "= 0 : 정규분포  \n",
    "&lt; 0 : 뾰족, 꼬리가 두툼\n",
    "&gt; 0 : 편평, 꼬리가 얇음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78907cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kurtosis\t: 0.0714438004616249\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kurtosis\n",
    "\n",
    "print (\"kurtosis\\t: {}\".format(kurtosis(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e498f43",
   "metadata": {},
   "source": [
    "## Spark DF with numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "882e95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x=np.random.randn(100)\n",
    "xPd=pd.DataFrame(x, columns=['x'], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a079d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as functions\n",
    "\n",
    "# df=spark.createDataFrame(xPd)\n",
    "\n",
    "# df.select(f.skewness(df['x']), f.kurtosis(df['x'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3dc53",
   "metadata": {},
   "source": [
    "### 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a00d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple mean of x = -0.060\n",
      "numpy mean of X = -0.060\n"
     ]
    }
   ],
   "source": [
    "print (\"simple mean of x = {:.3f}\".format(float(sum(X))/len(X)))\n",
    "\n",
    "xbar=np.mean(X)\n",
    "print (\"numpy mean of X = {:.3f}\".format(xbar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d189c",
   "metadata": {},
   "source": [
    "### 분산\n",
    "\n",
    "분산 variance나 표준편차 Standard Deviation은 평균으로부터 얼마나 멀리 떨어져 또는 흩어져 분포하는지 알려주는 값이다.\n",
    "\n",
    "- 분산은 평균에서 관측값을 뺀 차이값을 제곱한 후, n으로 나누어 평균을 계산한다. 제곱을 하지 않고 차이값을 더하면 0이 나오므로 제곱을 한다.\n",
    "- 분산을 제곱근하면 표준편차가 된다.\n",
    "- 분산보다는 표준편차가 더 자주 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8cf434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9602858529822947\n"
     ]
    }
   ],
   "source": [
    "X=x\n",
    "\n",
    "#식으로 표현하기\n",
    "print(np.sqrt(sum( [ (x-xbar)**2 for x in X ] )/len(X))) # ddof=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e45bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9651235957056545\n"
     ]
    }
   ],
   "source": [
    "# 자유도 반영\n",
    "print(np.sqrt(sum( [ (x-xbar)**2 for x in X ] )/(len(X)-1))) # ddof=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "884fa1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960285852982295\n",
      "0.9651235957056546\n"
     ]
    }
   ],
   "source": [
    "# Numpy로 계산하기\n",
    "\n",
    "print(np.std(X)) # ddof=0\n",
    "print(np.std(X, ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d27ad",
   "metadata": {},
   "source": [
    "### Z-Score (Nomalization)\n",
    "\n",
    "표준편차의 배수로 떨어진 정도를 정규화(표준화) 할 때 사용하는 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30dbca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28894319954075576 0.48994713455480726 -0.8647090729049615 -1.9989417049849068 -0.1101438808286719 1.0572328196201912 -0.9207748750020068 0.8169259796956264 0.6573131849397418 -0.20660824539848913 -1.2994557320477396 -0.45796455822238513 0.20871303130541902 0.7000134379598231 -0.805263317144137 -0.8353940944731141 2.022671962134407 -1.0479013227155491 -0.43593370662778985 -0.9147166780503968 -0.38800591768745063 1.155466155047204 -2.027983490928696 -0.355374218521076 -1.433726246856301 1.1371362336429984 0.07827049813055685 -1.683814413959942 -0.25950286418194635 -0.23584179821817594 0.7014256192943231 -0.2646923729939054 0.5626019662914712 0.7896891620809198 -1.2919894023241216 1.168388488627053 -0.11744590563492421 0.6981021514002228 1.999623111735511 -1.7745431781422316 0.44006407792149477 -0.4485542583395532 -1.0468928428688136 -1.3570815527412934 0.47217408475066547 1.1767255752564787 -0.4101329436158406 -0.15250627424010718 0.24115372158279597 -1.0264891160124103 -0.3656267972189368 -0.851971402999577 1.3467631206789268 -0.22282742040483833 0.008808609211772518 0.48639960511672725 -1.1053276061545225 -0.08490802657106647 1.6278788035981004 -1.4784832769339078 1.9675716080051275 2.3998222536941336 0.8819678821447685 0.9492321134716581 -1.4046298495486664 -0.6917272570345497 -0.6075501816669683 0.4437227601996473 -0.8720480340423649 -0.19473342080706374 -0.07976849419661575 -0.9136854500482804 1.7548662896661018 1.5987685856789808 -0.30817731125970804 1.3056988732645765 1.417478613005925 -1.1449391872980748 0.973648352188012 0.13968747296869574 1.3204646426244087 -0.9778115869672238 0.22930909436902214 0.06735694756271336 0.8913039594127506 1.3440378631446572 -0.9793677812805445 -0.8374524181149139 0.17363922936958562 0.2340549275901914 -0.7194868102955143 0.2555923198555802 -1.2000925440242156 -1.1820246021573921 0.09107574679586886 -0.2038251209919756 -0.27696278320796247 -0.2902492996140769 1.9175390230294191 0.47679035634607597 "
     ]
    }
   ],
   "source": [
    "# 계산식\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "xbar=np.mean(X)\n",
    "sigmax=np.std(X) #ddof=0\n",
    "sx=np.std(X,ddof=1)\n",
    "for x in X:\n",
    "    #zscore=(x-xbar)/sx\n",
    "    zscore=(x-xbar)/sigmax\n",
    "    print (zscore, end= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4220097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2889432 ,  0.48994713, -0.86470907, -1.9989417 , -0.11014388,\n",
       "        1.05723282, -0.92077488,  0.81692598,  0.65731318, -0.20660825,\n",
       "       -1.29945573, -0.45796456,  0.20871303,  0.70001344, -0.80526332,\n",
       "       -0.83539409,  2.02267196, -1.04790132, -0.43593371, -0.91471668,\n",
       "       -0.38800592,  1.15546616, -2.02798349, -0.35537422, -1.43372625,\n",
       "        1.13713623,  0.0782705 , -1.68381441, -0.25950286, -0.2358418 ,\n",
       "        0.70142562, -0.26469237,  0.56260197,  0.78968916, -1.2919894 ,\n",
       "        1.16838849, -0.11744591,  0.69810215,  1.99962311, -1.77454318,\n",
       "        0.44006408, -0.44855426, -1.04689284, -1.35708155,  0.47217408,\n",
       "        1.17672558, -0.41013294, -0.15250627,  0.24115372, -1.02648912,\n",
       "       -0.3656268 , -0.8519714 ,  1.34676312, -0.22282742,  0.00880861,\n",
       "        0.48639961, -1.10532761, -0.08490803,  1.6278788 , -1.47848328,\n",
       "        1.96757161,  2.39982225,  0.88196788,  0.94923211, -1.40462985,\n",
       "       -0.69172726, -0.60755018,  0.44372276, -0.87204803, -0.19473342,\n",
       "       -0.07976849, -0.91368545,  1.75486629,  1.59876859, -0.30817731,\n",
       "        1.30569887,  1.41747861, -1.14493919,  0.97364835,  0.13968747,\n",
       "        1.32046464, -0.97781159,  0.22930909,  0.06735695,  0.89130396,\n",
       "        1.34403786, -0.97936778, -0.83745242,  0.17363923,  0.23405493,\n",
       "       -0.71948681,  0.25559232, -1.20009254, -1.1820246 ,  0.09107575,\n",
       "       -0.20382512, -0.27696278, -0.2902493 ,  1.91753902,  0.47679036])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zscore()는 scipy.stats에서 제공하고 있다.\n",
    "\n",
    "from scipy import stats\n",
    "stats.zscore(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a707c",
   "metadata": {},
   "source": [
    "### cdf - 누적확률계산\n",
    "추론통계에서 확률을 계산하는 것은 중요하다. p-value와 신뢰구간의 계산에 필요하다. \n",
    "cdf Cumulative Distribution Function은 누적확률을 의미한다. \n",
    "정규분포에서 평균 loc=0, 표준편차 scale=1을 기본 값으로, cdf(0)은 '0'또는 그 이하의 값을 누적한 확률을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "849421f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.cdf(0, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44f5a4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826894921370859"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " norm.cdf(1) - norm.cdf(-1) #모집단의 68.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab62895f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544997361036416"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(2) - norm.cdf(-2) #모집단 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2813314",
   "metadata": {},
   "source": [
    "### tscore\n",
    "표본의 크기가 크면 모집단과 차이가 없는데, 표본이 작으면 어떻게 될까? 이 경우 사용하는 것이 t분포이다.   \n",
    "t분포는 정규분포와 유사한 모양을 가지고 있지만, 꼬리가 두툼한 특징을 가지고 있다.    \n",
    "따라서 평균에서 멀어진 값을 샘플링할 확률이 높아지게 된다. n이 일정 규모로 커지면 t분포와 정규분포와 유사하게 된다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a90f420e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500000000000002"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "t.cdf(1, 1) # dof 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce3f05",
   "metadata": {},
   "source": [
    "# Outlier\n",
    "\n",
    "정규분포를 따른다고 했을 경우, 분포의 표준편차 범위 -3 ~ 3안에 99.7%가 포함되고 그 밖의 값은 0.3%에 불과하여 발생하기 극히 어렵다. 이러한 일정 범위를 넘어선 값은 이상값이다.   \n",
    "\n",
    "이상값은 분석에 영향을 미치며, 몸무게-키의 회귀분석선을 생각해보면 이상 몸무게는 선을 틀어지게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa8a1ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 5, 1, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filterOutliers(data):\n",
    "    m = np.mean(data)\n",
    "    s = np.std(data)\n",
    "    filtered = [d for d in data if (m - 2 * s < d < m + 2 * s)]\n",
    "    return filtered\n",
    "\n",
    "d = [2,4,5,1,6,5,40]\n",
    "filtered_d = filterOutliers(d)\n",
    "print (filtered_d)\n",
    "\n",
    "\n",
    "# 40은 Outlier로 판단하여 전처리하여 제외한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64507ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
